{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95e0139a",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "### Integrantes\n",
    "* Sergio Orellana 221122\n",
    "* Rodrigo Mansilla 22611\n",
    "* Ricardo Chuy 221007"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602f4b8b",
   "metadata": {},
   "source": [
    "**1. Una homograf√≠a ùêª es una matriz de 3 √ó 3. Explique matem√°ticamente por qu√©, aunque tiene 9 elementos, solo posee 8 grados de libertad (GDL)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068c094b",
   "metadata": {},
   "source": [
    "Una homograf√≠a act√∫a sobre puntos en coordenadas homog√©neas $x \\in \\mathbb{P}^2$ mediante la relaci√≥n de equivalencia\n",
    "\n",
    "$$\n",
    "x' \\sim Hx,\n",
    "$$\n",
    "\n",
    "donde $x' \\sim y$ significa que existen escalares no nulos $\\lambda \\neq 0$ tales que $x' = \\lambda y$. \n",
    "\n",
    "En consecuencia, si multiplicamos $H$ por cualquier escalar no nulo $\\alpha \\neq 0$, la transformaci√≥n inducida en el plano proyectivo no cambia:\n",
    "\n",
    "$$\n",
    "x' \\sim Hx \\quad \\Longrightarrow \\quad x' \\sim (\\alpha H)x.\n",
    "$$\n",
    "\n",
    "Para verlo de forma expl√≠cita en coordenadas euclidianas, sea $x = (u,v,1)^\\top$ y\n",
    "\n",
    "$$\n",
    "Hx = \\begin{bmatrix}p\\\\ q\\\\ r\\end{bmatrix}, \\qquad r \\neq 0.\n",
    "$$\n",
    "\n",
    "La proyecci√≥n a coordenadas no homog√©neas es\n",
    "\n",
    "$$\n",
    "\\pi(Hx)=\\left(\\frac{p}{r},\\frac{q}{r}\\right).\n",
    "$$\n",
    "\n",
    "Ahora, si usamos $\\alpha H$:\n",
    "\n",
    "$$\n",
    "(\\alpha H)x=\\alpha\\begin{bmatrix}p\\\\ q\\\\ r\\end{bmatrix}\n",
    "\\quad\\Rightarrow\\quad\n",
    "\\pi((\\alpha H)x)=\\left(\\frac{\\alpha p}{\\alpha r},\\frac{\\alpha q}{\\alpha r}\\right)=\\left(\\frac{p}{r},\\frac{q}{r}\\right)=\\pi(Hx).\n",
    "$$\n",
    "\n",
    "Por consiguiente, la homograf√≠a no es un objeto con 9 par√°metros ‚Äúobservables‚Äù, sino una clase de equivalencia $[H]$ definida hasta escala. Dicho de otro modo, $H$ vive en el espacio proyectivo $\\mathbb{P}^8$, as√≠ que sus grados de libertad son\n",
    "\n",
    "$$\n",
    "9\\ \\text{par√°metros} \\ -\\ 1\\ \\text{escala} \\ =\\ 8\\ \\text{GDL}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72015be4",
   "metadata": {},
   "source": [
    "**a. Adicionalmente, respoda. Si tuvi√©ramos una c√°mara que solo rota sobre su eje √≥ptico (sin\n",
    "traslaci√≥n ni cambio de perspectiva), ¬øla matriz de transformaci√≥n sigue teniendo 8 GDL o\n",
    "se reduce? Demuestre la estructura de dicha matriz simplificad**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a01c79b",
   "metadata": {},
   "source": [
    "Si la c√°mara solo rota alrededor de su eje √≥ptico, el movimiento es una rotaci√≥n 3D $R_z(\\theta)$ (sin traslaci√≥n). En un modelo pinhole con intr√≠nsecos constantes $K$, la homograf√≠a entre dos vistas viene dada por\n",
    "\n",
    "$$\n",
    "H = KRK^{-1}.\n",
    "$$\n",
    "\n",
    "En particular, para una rotaci√≥n alrededor del eje √≥ptico:\n",
    "\n",
    "$$\n",
    "R_z(\\theta)=\n",
    "\\begin{bmatrix}\n",
    "\\cos\\theta & -\\sin\\theta & 0\\\\\n",
    "\\sin\\theta & \\cos\\theta & 0\\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Si, adem√°s, tomamos un caso est√°ndar sin skew con $f$ y punto principal $(c_x,c_y)$,\n",
    "\n",
    "$$\n",
    "K=\n",
    "\\begin{bmatrix}\n",
    "f & 0 & c_x\\\\\n",
    "0 & f & c_y\\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix},\n",
    "\\qquad\n",
    "K^{-1}=\n",
    "\\begin{bmatrix}\n",
    "\\frac{1}{f} & 0 & -\\frac{c_x}{f}\\\\\n",
    "0 & \\frac{1}{f} & -\\frac{c_y}{f}\\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Entonces\n",
    "\n",
    "$$\n",
    "H = K R_z(\\theta) K^{-1}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\cos\\theta & -\\sin\\theta & c_x(1-\\cos\\theta)+c_y\\sin\\theta\\\\\n",
    "\\sin\\theta & \\cos\\theta & -c_x\\sin\\theta+c_y(1-\\cos\\theta)\\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "En contraste con una homograf√≠a general (8 GDL), aqu√≠ toda la transformaci√≥n queda parametrizada √∫nicamente por $\\theta$ cuando $K$ es fijo. Por lo tanto, los grados de libertad del movimiento (y de la homograf√≠a inducida) se reducen a $1$ GDL.\n",
    "\n",
    "Por ejemplo, si trabajamos en un sistema de coordenadas cuyo origen est√° en el punto principal (es decir, $c_x=c_y=0$), la matriz se simplifica a√∫n m√°s:\n",
    "\n",
    "$$\n",
    "H =\n",
    "\\begin{bmatrix}\n",
    "\\cos\\theta & -\\sin\\theta & 0\\\\\n",
    "\\sin\\theta & \\cos\\theta & 0\\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Aun cuando $H$ siga siendo una matriz $3\\times 3$, la restricci√≥n geom√©trica ‚Äúsolo rotaci√≥n sobre el eje √≥ptico‚Äù elimina pr√°cticamente todos los grados de libertad de una homograf√≠a arbitraria, dejando solo el √°ngulo de rotaci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73e0999",
   "metadata": {},
   "source": [
    "**2. En el algoritmo DLT (Direct Linear Transform), convertimos el problema ùë•‚Ä≤ = ùêªùë• en un sistema de la\n",
    "forma ùê¥‚Ñé = 0. Explique por qu√© buscamos el vector singular asociado al menor valor singular\n",
    "de ùê¥ en lugar de simplemente invertir la matriz. ¬øQu√© representa geom√©tricamente ese \"menor valor\n",
    "singular\" cuando los datos tienen ruido?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874ce011",
   "metadata": {},
   "source": [
    "En DLT, partimos de la relaci√≥n proyectiva $x' \\sim Hx$. Una manera est√°ndar de eliminar la escala desconocida es usar el producto cruz:\n",
    "\n",
    "$$\n",
    "x' \\times (Hx) = 0.\n",
    "$$\n",
    "\n",
    "Esta ecuaci√≥n genera restricciones lineales en los elementos de $H$ (apilados en $h=\\mathrm{vec}(H)$), de modo que obtenemos\n",
    "\n",
    "$$\n",
    "Ah=0,\n",
    "$$\n",
    "\n",
    "donde t√≠picamente $A \\in \\mathbb{R}^{2N\\times 9}$ si usamos $N$ correspondencias (dos ecuaciones independientes por punto). \n",
    "\n",
    "En primer lugar, **no ‚Äúinvertimos‚Äù $A$** porque:\n",
    "1) $A$ no es cuadrada en general ($2N\\times 9$), as√≠ que no existe una inversa cl√°sica.\n",
    "2) Incluso si fuera cuadrada en alg√∫n caso particular, el sistema es homog√©neo: $h$ solo se define hasta escala ($h \\sim \\alpha h$), por lo que hablar de ‚Äúsoluci√≥n por inversi√≥n‚Äù no es el enfoque correcto.\n",
    "3) Con ruido, el sistema **no tiene soluci√≥n exacta** $Ah=0$.\n",
    "\n",
    "En lugar de eso, buscamos el vector $h$ que minimiza el error algebraico bajo una normalizaci√≥n (para evitar la soluci√≥n trivial $h=0$). Es decir:\n",
    "\n",
    "$$\n",
    "\\min_{\\|h\\|=1} \\|Ah\\|.\n",
    "$$\n",
    "\n",
    "Si hacemos la descomposici√≥n en valores singulares (SVD)\n",
    "\n",
    "$$\n",
    "A = U\\Sigma V^\\top,\n",
    "$$\n",
    "\n",
    "y escribimos $h=V z$ con $\\|h\\|=\\|z\\|$, entonces\n",
    "\n",
    "$$\n",
    "\\|Ah\\|=\\|U\\Sigma V^\\top V z\\|=\\|\\Sigma z\\|.\n",
    "$$\n",
    "\n",
    "La norma $\\|\\Sigma z\\|$ se minimiza eligiendo $z$ como el vector can√≥nico asociado al **menor** valor singular $\\sigma_{\\min}$, es decir, $h$ es la **√∫ltima columna de $V$**.\n",
    "\n",
    "Geom√©tricamente, cuando hay ruido, $\\sigma_{\\min}$ mide ‚Äúqu√© tan cerca‚Äù est√° $A$ de ser rango-deficiente (el caso ideal donde existe un nullspace exacto de dimensi√≥n 1). En otras palabras, $\\sigma_{\\min}$ cuantifica el residual m√≠nimo posible:\n",
    "\n",
    "$$\n",
    "\\sigma_{\\min} = \\min_{\\|h\\|=1}\\|Ah\\|.\n",
    "$$\n",
    "\n",
    "Por consiguiente:\n",
    "- si los datos fueran perfectos, esperar√≠amos $\\sigma_{\\min}\\approx 0$ (nullspace casi exacto);\n",
    "- sin embargo, con ruido, $\\sigma_{\\min}>0$ y su magnitud refleja la inconsistencia introducida por el ruido y/o una mala configuraci√≥n geom√©trica (por ejemplo, puntos casi colineales o mala normalizaci√≥n).\n",
    "\n",
    "En s√≠ntesis, el ‚Äúmenor valor singular‚Äù es el indicador de la mejor compatibilidad algebraica de una homograf√≠a con los datos observados bajo ruido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af546a43",
   "metadata": {},
   "source": [
    "**3. Si usted selecciona 4 puntos para calcular ùêª, pero 3 de ellos son colineales (est√°n en la misma l√≠nea\n",
    "recta), el algoritmo fallar√°. Explique algebraicamente qu√© le sucede a la matriz ùê¥ del sistema DLT en\n",
    "este caso y por qu√© no tiene soluci√≥n √∫nica.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee871793",
   "metadata": {},
   "source": [
    "En el caso ideal (sin degeneraci√≥n), con 4 correspondencias obtenemos 8 ecuaciones independientes y, t√≠picamente, $\\mathrm{rank}(A)=8$, de modo que el nullspace de $A$ tiene dimensi√≥n 1 y define $h$ de forma √∫nica (hasta escala).\n",
    "\n",
    "Ahora supongamos que tres puntos de entrada $x_1,x_2,x_3$ son colineales. Entonces existe una recta $l$ tal que\n",
    "\n",
    "$$\n",
    "l^\\top x_i = 0 \\quad \\text{para } i\\in\\{1,2,3\\}.\n",
    "$$\n",
    "\n",
    "De igual forma consideremos cualquier vector $u\\in\\mathbb{R}^3$ y defina una familia de matrices\n",
    "\n",
    "$$\n",
    "H(\\tau)=H+\\tau\\,u\\,l^\\top, \\qquad \\tau\\in\\mathbb{R}.\n",
    "$$\n",
    "\n",
    "Para los puntos colineales:\n",
    "\n",
    "$$\n",
    "H(\\tau)x_i = Hx_i + \\tau\\,u\\,(l^\\top x_i) = Hx_i + \\tau\\,u\\cdot 0 = Hx_i.\n",
    "$$\n",
    "\n",
    "Es decir, **todas** las matrices $H(\\tau)$ inducen exactamente la misma proyecci√≥n sobre esos tres puntos (porque el t√©rmino a√±adido se anula en la recta $l$). Por lo tanto, las ecuaciones que esos puntos generan en $Ah=0$ no ‚Äúven‚Äù ciertas combinaciones de par√°metros: hay infinitas soluciones compatibles con esas tres correspondencias.\n",
    "\n",
    "Aunque el cuarto punto $x_4$ agrega restricciones adicionales, en general no alcanza para eliminar toda la ambig√ºedad creada por la colinealidad. En consecuencia, a nivel matricial ocurre que:\n",
    "- varias filas de $A$ se vuelven linealmente dependientes (o casi dependientes si hay ruido),\n",
    "- $\\mathrm{rank}(A)$ cae por debajo de 8,\n",
    "- el nullspace de $A$ pasa a tener dimensi√≥n mayor que 1 (no hay unicidad).\n",
    "\n",
    "Una se√±al clara en SVD es que, en lugar de un √∫nico valor singular cercano a cero, aparecen **varios** valores singulares peque√±os, reflejando m√∫ltiples direcciones $h$ con residuales muy parecidos:\n",
    "\n",
    "$$\n",
    "Ah \\approx 0 \\quad \\text{para varios } h \\text{ distintos}.\n",
    "$$\n",
    "\n",
    "En s√≠ntesis, la colinealidad hace que el sistema DLT quede subdeterminado: la matriz $A$ pierde rango y, por lo tanto, no existe una soluci√≥n √∫nica para la homograf√≠a."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c8a8b5",
   "metadata": {},
   "source": [
    "# Referencias\n",
    "\n",
    "- 41 Homographies ‚Äì Foundations of Computer Vision. (n.d.). https://visionbook.mit.edu/homography.html \n",
    "- Hartley, R., & Zisserman, A. (2004). Multiple view geometry in computer vision. In Cambridge University Press eBooks. https://doi.org/10.1017/cbo9780511811685 \n",
    "- OpenCV: Basic concepts of the homography explained with code. (n.d.). https://docs.opencv.org/4.x/d9/dab/tutorial_homography.html"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
